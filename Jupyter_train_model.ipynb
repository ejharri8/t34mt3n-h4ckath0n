{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30000 validated image filenames.\n",
      "Found 20000 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "#import statements\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Activation,MaxPooling2D,Dropout,Flatten\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "from keras import backend as K\n",
    "from keras.utils import plot_model\n",
    "\n",
    "#df is data from csv file\n",
    "filename_train_csv = \"data/train_free_throws.csv\"\n",
    "df=pd.read_csv(filename_train_csv, header = None)\n",
    "\n",
    "#change this csv for testing\n",
    "filename_test_csv = \"data/test_free_throws.csv\"\n",
    "mainDF=pd.read_csv(filename_test_csv, header = None)\n",
    "datagen=ImageDataGenerator() #rescale=1./255)\n",
    "\n",
    "\n",
    "df.columns = ['0','1']\n",
    "mainDF.columns = ['0','1']\n",
    "\n",
    "\n",
    "# main generator is the one for test data\n",
    "main_generator=datagen.flow_from_dataframe(dataframe=mainDF, directory=\"data/\", x_col=\"0\",\n",
    "                                           y_col=\"1\", class_mode=\"raw\", target_size=(320,180), batch_size=32)\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(dataframe=df, directory=\"data/\", x_col=\"0\",\n",
    "                                           y_col=\"1\", class_mode=\"raw\", target_size=(320,180), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kernel_size = (3,3)\n",
    "input_shape=(320,180,3)\n",
    "num_classes = 2  # True of False classification\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, kernel_size=model_kernel_size, activation='relu', input_shape= input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, kernel_size= model_kernel_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "937/937 [==============================] - 78s 83ms/step - loss: 0.0346 - accuracy: 0.9948 - precision: 0.1304 - recall: 0.9883 - val_loss: 2.9764 - val_accuracy: 0.9115 - val_precision: 0.0828 - val_recall: 0.9376\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-db02299d5459>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# training values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "#model.compile(optimizers.rmsprop(lr=0.0001),loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.compile(optimizers.rmsprop(lr=0.0001),loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\", precision, recall])\n",
    "\n",
    "STEP_SIZE_TRAIN = main_generator.n//main_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "hist = model.fit_generator(generator=main_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs = 1 )\n",
    "\n",
    "#score = model.evalutate(x_test,y_test, verbose = 0)\n",
    "\n",
    "# training values\n",
    "#acc = hist.history['acc']\n",
    "#loss_ = hist.history['loss']\n",
    "\n",
    "#print(\"test accuracy: \" , acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "#def inference(csv_file):\n",
    "csv_file = 'data/test_free_throws.csv'\n",
    "#load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "#load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "#... read csv file\n",
    "# df is data from csv file\n",
    "filename = csv_file\n",
    "df=pd.read_csv(filename, header = None)\n",
    "df.columns = ['0','1']\n",
    "valid_generator = datagen.flow_from_dataframe(dataframe=df, directory=\"data/\", x_col=\"0\",y_col=\"1\",\n",
    "                                            class_mode=\"raw\", target_size=(320,180), batch_size=32)\n",
    "\n",
    "\n",
    "loaded_model.compile(optimizers.rmsprop(lr=0.0001),loss=\"sparse_categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\", precision, recall])\n",
    "#... use the model to do inference\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "score = loaded_model.evaluate_generator(generator = valid_generator, steps = STEP_SIZE_VALID,\n",
    "                                 use_multiprocessing = False, verbose = 1 )\n",
    "\n",
    "print('\\n answer:\\n')\n",
    "print('Test loss:', score[0] )\n",
    "print('Test accuracy:', score[1] )\n",
    "print('Test recall:', score[2] )\n",
    "print('Test precision:', score[3] )\n",
    "print('\\n')\n",
    "\n",
    "#... compute accuracy,recall and precision score using 0.5 threshold\n",
    "#return {'accuracy':accuracy, 'recall':recall, 'precision':precision}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(filename='data/10031/jpg/320_180/thumb00110000.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras.models import Model\\nlayer_outputs = [layer.output for layer in model.layers]\\nactivation_model = Model(inputs=model.input, outputs=layer_outputs)\\nactivations = activation_model.predict_generator(generator = valid_generator, steps = STEP_SIZE_VALID, verbose = 1 )#(X_train[10].reshape(1,28,28,1))\\n \\ndef display_activation(activations, col_size, row_size, act_index): \\n    activation = activations[act_index]\\n    activation_index=0\\n    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\\n    for row in range(0,row_size):\\n        for col in range(0,col_size):\\n            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\\n            activation_index += 1\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "heatmap_generator=datagen.flow_from_dataframe(dataframe=mainDF, directory=\"data/\", x_col=\"0\",\n",
    "                                           y_col=\"1\", classes = [1,0] ,class_mode=None, target_size=(180,320), batch_size=1)\n",
    "\n",
    "x= heatmap_generator.next()\n",
    "\n",
    "from keras.models import Model\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict_generator(generator = valid_generator, steps = STEP_SIZE_VALID, verbose = 1 )#(X_train[10].reshape(1,28,28,1))\n",
    " \n",
    "def display_activation(activations, col_size, row_size, act_index): \n",
    "    activation = activations[act_index]\n",
    "    activation_index=0\n",
    "    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n",
    "    for row in range(0,row_size):\n",
    "        for col in range(0,col_size):\n",
    "            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n",
    "            activation_index += 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_activation(activations, 8, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 2), (20000, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_train_csv = \"data/free_throw_training_data.csv\"\n",
    "df=pd.read_csv(filename_train_csv, header = None)\n",
    "\n",
    "cut = 30000\n",
    "cut_end = cut + 20000\n",
    "df1 = df.iloc[:cut, :]\n",
    "df2 = df.iloc[cut:cut_end, :]\n",
    "df1.shape, df2.shape\n",
    "\n",
    "df1.to_csv(\"data/test_free_throws.csv\", header= None, index=False)\n",
    "df2.to_csv(\"data/train_free_throws.csv\", header= None, index=False)\n",
    "\n",
    "df1.shape, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16380 validated image filenames.\n",
      "evaluate model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 14032 invalid image filename(s) in x_col=\"0\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Activation,MaxPooling2D,Dropout,Flatten\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#import numpy as np\n",
    "from keras import optimizers\n",
    "import os\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "import sys\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "    Only computes a batch-wise average of recall.\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "#def inference(csv_file):\n",
    "#load json and create model\n",
    "input_file = 'dunk_layup_test_data.csv'\n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "#load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "\n",
    "#... read csv file\n",
    "# df is data from csv file\n",
    "\n",
    "df=pd.read_csv(input_file, header = None)\n",
    "df.columns = ['0','1']\n",
    "datagen=ImageDataGenerator() \n",
    "valid_generator = datagen.flow_from_dataframe(dataframe=df, directory=\"data/\", x_col=\"0\",y_col=\"1\",\n",
    "                                            class_mode=\"raw\", target_size=(320,180), batch_size=30)\n",
    "\n",
    "loaded_model.compile(optimizers.rmsprop(lr=0.0001),loss=\"sparse_categorical_crossentropy\", \n",
    "          metrics=[\"accuracy\", precision, recall])\n",
    "\n",
    "print('evaluate model')\n",
    "#... use the model to do inference\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-73b22c5963d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTEP_SIZE_VALID\u001b[0m  \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccuracy_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1789\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1790\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1791\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    399\u001b[0m             outs = model.test_on_batch(x, y,\n\u001b[1;32m    400\u001b[0m                                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                                        reset_metrics=False)\n\u001b[0m\u001b[1;32m    402\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1557\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1559\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/keras/backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score = loaded_model.evaluate_generator(generator = valid_generator, steps = STEP_SIZE_VALID  )\n",
    "\n",
    "\n",
    "# accuracy\n",
    "accuracy_output = score[1]\n",
    "\n",
    "# recall = truePositives / (truePositives + falseNegatives) backend.epislon()\n",
    "recall_output = score[2]\n",
    "\n",
    "# precision = truePositives / (truePositives + falsePositives)\n",
    "precision_output = score[3]\n",
    "\n",
    "#... compute accuracy,recall and precision score using 0.5 threshold\n",
    "#return {'accuracy':accuracy_output, 'recall':recall_output, 'precision':precision_output}\n",
    "\n",
    "\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    #input_file = sys.argv[1] \n",
    "\n",
    "#ans = inference(input_file)\n",
    "#print('done\\n')\n",
    "#print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
